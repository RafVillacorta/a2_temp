{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - CSI4106\n",
    "Group: assignment_2_49\n",
    "\n",
    " Tristan Pender - 300065847 - tpend052@uottawa.ca\n",
    "\n",
    " Rafael Villacorta - 300061289 - rvill094@uottawa.ca\n",
    " \n",
    " Hans Barrea - 300080843 - hbarr050@uottawa.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5312), started 1 day, 2:39:39 ago. (Use '!kill 5312' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a2d578ce862c6b48\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a2d578ce862c6b48\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the relevant datasets (15/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the shape of the train dataset (15026, 4) \n",
      "\n",
      "Here is the shape of the test dataset (4696, 4) \n",
      "\n",
      "Here is the shape of the val dataset (3757, 4) \n",
      "\n",
      "Here are the column names in the dataframe \n",
      "\n",
      "age\n",
      "ethnicity\n",
      "gender\n",
      "img_name\n",
      "\n",
      " End of the column names. \n",
      "Here is the proportional distribution of gender in train \n",
      "0    7864\n",
      "1    7162\n",
      "Name: gender, dtype: int64 \n",
      " ********\n",
      "Here is the proportional distribution of gender in test \n",
      "0    2456\n",
      "1    2240\n",
      "Name: gender, dtype: int64 \n",
      " ********\n",
      "Here is the proportional distribution of gender in val \n",
      "0    1965\n",
      "1    1792\n",
      "Name: gender, dtype: int64 \n",
      " ********\n",
      "Here is the proportional distribution of ethnicity in train \n",
      "0.0    6372\n",
      "1.0    2869\n",
      "3.0    2524\n",
      "2.0    2186\n",
      "4.0    1075\n",
      "Name: ethnicity, dtype: int64 \n",
      " ********\n",
      "Here is the proportional distribution of ethnicity in test \n",
      "0    1991\n",
      "1     896\n",
      "3     790\n",
      "2     683\n",
      "4     336\n",
      "Name: ethnicity, dtype: int64 \n",
      " ********\n",
      "Here is the proportional distribution of ethnicity in val \n",
      "0    1593\n",
      "1     717\n",
      "3     632\n",
      "2     547\n",
      "4     268\n",
      "Name: ethnicity, dtype: int64 \n",
      " ********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the datasets using the csv files train, val and test \n",
    "# (3)\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "val_df = pd.read_csv(\"./data/val.csv\")\n",
    "\n",
    "\n",
    "# print the shapes of the dataframes \n",
    "# (3)\n",
    "print(f\"Here is the shape of the train dataset {train_df.shape} \\n\")\n",
    "\n",
    "print(f\"Here is the shape of the test dataset {test_df.shape} \\n\")\n",
    "\n",
    "print(f\"Here is the shape of the val dataset {val_df.shape} \\n\")\n",
    "\n",
    "\n",
    "\n",
    "# print the column names from either one of the dataframes \n",
    "# (1)\n",
    "print(f\"Here are the column names in the dataframe \\n\")\n",
    "\n",
    "for i in train_df.columns : \n",
    "    print(i)\n",
    "\n",
    "print(f\"\\n End of the column names. \")\n",
    "\n",
    "train_df[\"ethnicity\"] = np.asarray(train_df[\"ethnicity\"]).astype('float32').reshape((-1,1))\n",
    "# print the proportional distribution of gender in all three datasets(i.e., number of male and female) \n",
    "# (3)\n",
    "train_df_gender_class_distr = train_df['gender'].value_counts()\n",
    "test_df_gender_class_distr = test_df['gender'].value_counts()\n",
    "val_df_gender_class_distr = val_df['gender'].value_counts()\n",
    "\n",
    "print(f\"Here is the proportional distribution of gender in train \\n{train_df_gender_class_distr} \\n ********\")\n",
    "print(f\"Here is the proportional distribution of gender in test \\n{test_df_gender_class_distr} \\n ********\")\n",
    "print(f\"Here is the proportional distribution of gender in val \\n{val_df_gender_class_distr} \\n ********\")\n",
    "\n",
    "# print the proportional distribution of ethnicity in all three datasets \n",
    "# (3)\n",
    "train_df_ethnicity_class_distr = train_df['ethnicity'].value_counts()\n",
    "test_df_ethnicity_class_distr = test_df['ethnicity'].value_counts()\n",
    "val_df_ethnicity_class_distr = val_df['ethnicity'].value_counts()\n",
    "print(f\"Here is the proportional distribution of ethnicity in train \\n{train_df_ethnicity_class_distr} \\n ********\")\n",
    "print(f\"Here is the proportional distribution of ethnicity in test \\n{test_df_ethnicity_class_distr} \\n ********\")\n",
    "print(f\"Here is the proportional distribution of ethnicity in val \\n{val_df_ethnicity_class_distr} \\n ********\")\n",
    "\n",
    "# plot the age distribution from the training dataset where the x-axis plots the age and the y-axis depicts the count of individuals within each age group. For example, individuals with age=1 are: \n",
    "# (2)\n",
    "train_df.age.plot(kind='hist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ImageDataGenerators (22/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15026 validated image filenames.\n",
      "Found 3757 validated image filenames.\n",
      "Found 4696 validated image filenames.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ImageDataGenerator is an iterator.\n",
    "\n",
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size = 16\n",
    "\n",
    "# create the ImageDataGenerator with rescaling that will generate batched tensors representing images with real-time data augmentation\n",
    "# use at least two of the augmentation strategies. For example, fill_mode='nearest'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (3)\n",
    "train_img_gen = ImageDataGenerator(\n",
    "   fill_mode= \"nearest\",\n",
    "   rotation_range=40,\n",
    "   width_shift_range=0.2,\n",
    "   height_shift_range=0.2,\n",
    "   rescale=None\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance to link the image folder and the dataframe.\n",
    "# also include the, batch size, image size and the seed.\n",
    "# make sure to include the following arguments\n",
    "# color_mode='grayscale', class_mode='multi_output'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (5)\n",
    "train_flow_from_dataframe = train_img_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    rescale=1./255,\n",
    "    directory= \"./data/images/train/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\",\"ethnicity\",\"gender\"],\n",
    "    color_mode= \"grayscale\",\n",
    "    class_mode=\"multi_output\",\n",
    "    seed=SEED,\n",
    "    target_size=(256, 256),\n",
    "\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# similarly, create an ImageDataGenerator for the validation dataset and make sure not to use any of th eaugmentation strategies except rescaling the image\n",
    "# (2)\n",
    "val_img_gen = ImageDataGenerator(\n",
    "    rescale= None\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance with the same arguments as above\n",
    "# make sure to specify the following arguments:\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "\n",
    "val_flow_from_dataframe = val_img_gen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    rescale=1./255,\n",
    "    directory= \"./data/images/val/\",\n",
    "    x_col= \"img_name\",\n",
    "    y_col= [\"age\",\"ethnicity\",\"gender\"],\n",
    "    color_mode= \"grayscale\",\n",
    "    class_mode=\"multi_output\",\n",
    "    seed=SEED,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(256, 256),\n",
    "\n",
    "    shuffle=False    \n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the val_img_gen instance to link the test dataframe and the test data folder\n",
    "# In addition, make sure to specify the following arguments\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "test_generator = val_img_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory= \"./data/images/test/\",\n",
    "    x_col= \"img_name\",\n",
    "    rescale=1./255,\n",
    "    y_col= [\"age\",\"ethnicity\",\"gender\"],\n",
    "    color_mode= \"grayscale\",\n",
    "    class_mode=\"multi_output\",\n",
    "    seed=SEED,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(256, 256),\n",
    "\n",
    "    shuffle=False    \n",
    ")\n",
    "\n",
    "\n",
    "# enumerate through the validation data generator created above and plot first grayscale image \n",
    "# (2)\n",
    "# generate samples and plot\n",
    "\n",
    "plt.plot(figsize=(15,15))\n",
    "\n",
    "\n",
    "\n",
    "for i, element in enumerate(val_flow_from_dataframe):\n",
    "    image = element[0].astype('uint8')\n",
    "    # plot image\n",
    "    plt.plot()\n",
    "    img_plot = plt.imshow(image[0], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model (44/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 255, 255, 32) 160         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 127, 127, 32) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 125, 125, 64) 18496       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 41, 41, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 41, 41, 64)   4160        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 40, 40, 128)  32896       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 40, 40, 128)  16512       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 40, 40, 128)  16512       dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 204800)       0           dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense4 (Dense)                  (None, 128)          26214528    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense5 (Dense)                  (None, 128)          16512       dense4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_age1 (Dense)              (None, 512)          66048       dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_ethinicity1 (Dense)       (None, 512)          66048       dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_gender1 (Dense)           (None, 512)          66048       dense5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_age2 (Dense)              (None, 256)          131328      dense_age1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_ethinicity2 (Dense)       (None, 512)          262656      dense_ethinicity1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_gender2 (Dense)           (None, 256)          131328      dense_gender1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_age3 (Dense)              (None, 256)          65792       dense_age2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_ethinicity3 (Dense)       (None, 256)          131328      dense_ethinicity2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_gender3 (Dense)           (None, 256)          65792       dense_gender2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_age4 (Dense)              (None, 128)          32896       dense_age3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_ethinicity4 (Dense)       (None, 128)          32896       dense_ethinicity3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_gender4 (Dense)           (None, 128)          32896       dense_gender3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_age5 (Dense)              (None, 64)           8256        dense_age4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_ethinicity5 (Dense)       (None, 128)          16512       dense_ethinicity4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_gender5 (Dense)           (None, 64)           8256        dense_gender4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "age_output (Dense)              (None, 1)            65          dense_age5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ethnicity_output (Dense)        (None, 5)            645         dense_ethinicity5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Dense)           (None, 1)            65          dense_gender5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 27,438,631\n",
      "Trainable params: 27,438,631\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "  2/939 [..............................] - ETA: 31:08 - loss: 1058.0039 - age_output_loss: 938706.1250 - ethnicity_output_loss: 13.5022 - gender_output_loss: 235.8950 - age_output_mean_squared_error: 938706.1250 - age_output_accuracy: 0.0000e+00 - ethnicity_output_mean_squared_error: 2.0075 - ethnicity_output_accuracy: 0.4062 - gender_output_mean_squared_error: 0.4744 - gender_output_accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.8298s vs `on_train_batch_end` time: 3.1564s). Check your callbacks.\n",
      "940/939 [==============================] - ETA: 0s - loss: 3.6293 - age_output_loss: 2790.2361 - ethnicity_output_loss: 1.5309 - gender_output_loss: 1.3720 - age_output_mean_squared_error: 2790.2361 - age_output_accuracy: 0.0469 - ethnicity_output_mean_squared_error: 2.9750 - ethnicity_output_accuracy: 0.4197 - gender_output_mean_squared_error: 0.2769 - gender_output_accuracy: 0.5098INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "940/939 [==============================] - 852s 906ms/step - loss: 3.6293 - age_output_loss: 2790.2361 - ethnicity_output_loss: 1.5309 - gender_output_loss: 1.3720 - age_output_mean_squared_error: 2790.2361 - age_output_accuracy: 0.0469 - ethnicity_output_mean_squared_error: 2.9750 - ethnicity_output_accuracy: 0.4197 - gender_output_mean_squared_error: 0.2769 - gender_output_accuracy: 0.5098 - val_loss: 1.3909 - val_age_output_loss: 853.4951 - val_ethnicity_output_loss: 1.8697 - val_gender_output_loss: 0.7009 - val_age_output_mean_squared_error: 853.4951 - val_age_output_accuracy: 0.0490 - val_ethnicity_output_mean_squared_error: 3.0559 - val_ethnicity_output_accuracy: 0.4240 - val_gender_output_mean_squared_error: 0.2538 - val_gender_output_accuracy: 0.5230\n",
      "Epoch 2/5\n",
      "940/939 [==============================] - ETA: 0s - loss: 0.9179 - age_output_loss: 431.7859 - ethnicity_output_loss: 1.4486 - gender_output_loss: 0.6826 - age_output_mean_squared_error: 431.7859 - age_output_accuracy: 0.0470 - ethnicity_output_mean_squared_error: 2.9759 - ethnicity_output_accuracy: 0.4237 - gender_output_mean_squared_error: 0.2439 - gender_output_accuracy: 0.5596INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "940/939 [==============================] - 814s 866ms/step - loss: 0.9179 - age_output_loss: 431.7859 - ethnicity_output_loss: 1.4486 - gender_output_loss: 0.6826 - age_output_mean_squared_error: 431.7859 - age_output_accuracy: 0.0470 - ethnicity_output_mean_squared_error: 2.9759 - ethnicity_output_accuracy: 0.4237 - gender_output_mean_squared_error: 0.2439 - gender_output_accuracy: 0.5596 - val_loss: 0.8016 - val_age_output_loss: 355.5945 - val_ethnicity_output_loss: 1.4003 - val_gender_output_loss: 0.6120 - val_age_output_mean_squared_error: 355.5945 - val_age_output_accuracy: 0.0490 - val_ethnicity_output_mean_squared_error: 2.9722 - val_ethnicity_output_accuracy: 0.4477 - val_gender_output_mean_squared_error: 0.2109 - val_gender_output_accuracy: 0.7035\n",
      "Epoch 3/5\n",
      "940/939 [==============================] - ETA: 0s - loss: 0.8182 - age_output_loss: 363.5020 - ethnicity_output_loss: 1.3987 - gender_output_loss: 0.6297 - age_output_mean_squared_error: 363.5020 - age_output_accuracy: 0.0470 - ethnicity_output_mean_squared_error: 2.9816 - ethnicity_output_accuracy: 0.4408 - gender_output_mean_squared_error: 0.2185 - gender_output_accuracy: 0.6582INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "940/939 [==============================] - 849s 903ms/step - loss: 0.8182 - age_output_loss: 363.5020 - ethnicity_output_loss: 1.3987 - gender_output_loss: 0.6297 - age_output_mean_squared_error: 363.5020 - age_output_accuracy: 0.0470 - ethnicity_output_mean_squared_error: 2.9816 - ethnicity_output_accuracy: 0.4408 - gender_output_mean_squared_error: 0.2185 - gender_output_accuracy: 0.6582 - val_loss: 0.7186 - val_age_output_loss: 265.0352 - val_ethnicity_output_loss: 1.3482 - val_gender_output_loss: 0.6376 - val_age_output_mean_squared_error: 265.0352 - val_age_output_accuracy: 0.0490 - val_ethnicity_output_mean_squared_error: 2.9860 - val_ethnicity_output_accuracy: 0.4839 - val_gender_output_mean_squared_error: 0.2080 - val_gender_output_accuracy: 0.7083\n",
      "Epoch 4/5\n",
      "940/939 [==============================] - 866s 921ms/step - loss: 0.7684 - age_output_loss: 324.9564 - ethnicity_output_loss: 1.3812 - gender_output_loss: 0.6106 - age_output_mean_squared_error: 324.9564 - age_output_accuracy: 0.0470 - ethnicity_output_mean_squared_error: 2.9833 - ethnicity_output_accuracy: 0.4435 - gender_output_mean_squared_error: 0.2094 - gender_output_accuracy: 0.6778 - val_loss: 0.7465 - val_age_output_loss: 279.7594 - val_ethnicity_output_loss: 1.3651 - val_gender_output_loss: 0.6605 - val_age_output_mean_squared_error: 279.7594 - val_age_output_accuracy: 0.0490 - val_ethnicity_output_mean_squared_error: 2.9783 - val_ethnicity_output_accuracy: 0.4355 - val_gender_output_mean_squared_error: 0.1931 - val_gender_output_accuracy: 0.7325\n",
      "Epoch 5/5\n",
      "940/939 [==============================] - ETA: 0s - loss: 0.7454 - age_output_loss: 309.2747 - ethnicity_output_loss: 1.3649 - gender_output_loss: 0.5993 - age_output_mean_squared_error: 309.2747 - age_output_accuracy: 0.0469 - ethnicity_output_mean_squared_error: 2.9854 - ethnicity_output_accuracy: 0.4533 - gender_output_mean_squared_error: 0.2045 - gender_output_accuracy: 0.6884INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "940/939 [==============================] - 878s 934ms/step - loss: 0.7454 - age_output_loss: 309.2747 - ethnicity_output_loss: 1.3649 - gender_output_loss: 0.5993 - age_output_mean_squared_error: 309.2747 - age_output_accuracy: 0.0469 - ethnicity_output_mean_squared_error: 2.9854 - ethnicity_output_accuracy: 0.4533 - gender_output_mean_squared_error: 0.2045 - gender_output_accuracy: 0.6884 - val_loss: 0.6428 - val_age_output_loss: 245.0447 - val_ethnicity_output_loss: 1.2945 - val_gender_output_loss: 0.5365 - val_age_output_mean_squared_error: 245.0447 - val_age_output_accuracy: 0.0490 - val_ethnicity_output_mean_squared_error: 2.9808 - val_ethnicity_output_accuracy: 0.4818 - val_gender_output_mean_squared_error: 0.1774 - val_gender_output_accuracy: 0.7378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e21f99d00>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "inputs = keras.Input(shape=(256,256,1)) \n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "x = layers.Conv2D(filters=32, kernel_size=2, activation=\"relu\")(inputs) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x) \n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)  \n",
    "x = layers.MaxPooling2D(pool_size=3)(x)  \n",
    "x = layers.Dense(64, activation='relu', name='dense1')(x) \n",
    "x = layers.Conv2D(filters=128, kernel_size=2, activation=\"relu\")(x)  \n",
    "x = layers.Dense(128, activation='relu', name='dense2')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense3')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense4')(x)\n",
    "x = layers.Dense(128, activation='relu', name='dense5')(x)\n",
    "# (10)\n",
    "\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "age_dense_layer = layers.Dense(512, activation='relu', name='dense_age1')(x)\n",
    "age_dense_layer = layers.Dense(256, activation='relu', name='dense_age2')(age_dense_layer)\n",
    "age_dense_layer = layers.Dense(256, activation='relu', name='dense_age3')(age_dense_layer)\n",
    "age_dense_layer = layers.Dense(128, activation='relu', name='dense_age4')(age_dense_layer)\n",
    "age_dense_layer = layers.Dense(64, activation='relu', name='dense_age5')(age_dense_layer)\n",
    "# (2)\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "age_output = layers.Dense(1, activation='linear', name='age_output')(age_dense_layer)\n",
    "# (2)\n",
    "\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "ethnicity_dense_layer = layers.Dense(512, activation='relu', name='dense_ethinicity1')(x)\n",
    "ethnicity_dense_layer = layers.Dense(512, activation='relu', name='dense_ethinicity2')(ethnicity_dense_layer)\n",
    "ethnicity_dense_layer = layers.Dense(256, activation='relu', name='dense_ethinicity3')(ethnicity_dense_layer)\n",
    "ethnicity_dense_layer = layers.Dense(128, activation='relu', name='dense_ethinicity4')(ethnicity_dense_layer)\n",
    "ethnicity_dense_layer = layers.Dense(128, activation='relu', name='dense_ethinicity5')(ethnicity_dense_layer)\n",
    "# (2)\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "ethnicity_output = layers.Dense(5, activation='softmax',kernel_initializer='constant', name='ethnicity_output')(ethnicity_dense_layer)\n",
    "# (2)\n",
    "\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "gender_dense_layer = layers.Dense(512, activation='relu', name='dense_gender1')(x)\n",
    "gender_dense_layer = layers.Dense(256, activation='relu', name='dense_gender2')(gender_dense_layer)\n",
    "gender_dense_layer = layers.Dense(256, activation='relu', name='dense_gender3')(gender_dense_layer)\n",
    "gender_dense_layer = layers.Dense(128, activation='relu', name='dense_gender4')(gender_dense_layer)\n",
    "gender_dense_layer = layers.Dense(64, activation='relu', name='dense_gender5')(gender_dense_layer)\n",
    "# (2)\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "gender_output = layers.Dense(1, activation='sigmoid', name='gender_output')(gender_dense_layer)\n",
    "# (2)\n",
    "\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "model = keras.models.Model(inputs=inputs, outputs=[age_output, ethnicity_output, gender_output])\n",
    "# (3)\n",
    "\n",
    "# print the model summary\n",
    "model.summary()\n",
    "# (0.5)\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "# (2)\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "losses = [\"mean_squared_error\",\"sparse_categorical_crossentropy\",'binary_crossentropy']\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "loss_weights=[0.001, 0.1, 0.5]\n",
    "model.compile(optimizer = optimizer, loss=losses, loss_weights= loss_weights, metrics=['mean_squared_error', 'accuracy'])\n",
    "# (2)\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# (2)\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# (2)\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = \"./models\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# (2)\n",
    "# For if the line below breaks everything: tf.profiler.experimental.stop()\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir= \"./logs\")\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# (2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=0.0001\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "steps_per_epoch=len(train_df)/batch_size\n",
    "validation_steps=len(val_df)/batch_size\n",
    "# (5)\n",
    "model.fit_generator(\n",
    "    train_flow_from_dataframe, \n",
    "    epochs = 5,\n",
    "    validation_data = val_flow_from_dataframe, \n",
    "    steps_per_epoch=len(train_df)/batch_size,\n",
    "    validation_steps=len(val_df)/batch_size,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoints, tensorboard],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data (14/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 60s 205ms/step - loss: 0.6443 - age_output_loss: 244.9373 - ethnicity_output_loss: 1.3046 - gender_output_loss: 0.5379 - age_output_mean_squared_error: 244.9373 - age_output_accuracy: 0.0492 - ethnicity_output_mean_squared_error: 2.9831 - ethnicity_output_accuracy: 0.4757 - gender_output_mean_squared_error: 0.1796 - gender_output_accuracy: 0.7323\n",
      "Ethnicity test accuracy is 0.4757240116596222 \n",
      "\n",
      "Gender test accuracy is 0.7323253750801086 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "# print only the test accuracy for ethnicity and gender predictions\n",
    "(4)\n",
    "scores = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Ethnicity test accuracy is {scores[7]} \\n\")\n",
    "print(f\"Gender test accuracy is {scores[9]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions using the test generator\n",
    "# (2)\n",
    "age_pred, ethnicity_pred, gender_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.93      0.62      1991\n",
      "           1       0.60      0.28      0.38       896\n",
      "           2       0.53      0.19      0.28       683\n",
      "           3       0.00      0.00      0.00       790\n",
      "           4       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.48      4696\n",
      "   macro avg       0.32      0.28      0.25      4696\n",
      "weighted avg       0.39      0.48      0.37      4696\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      2456\n",
      "           1       0.79      0.59      0.68      2240\n",
      "\n",
      "    accuracy                           0.73      4696\n",
      "   macro avg       0.75      0.73      0.72      4696\n",
      "weighted avg       0.74      0.73      0.73      4696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAF\\miniconda3\\envs\\A1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RAF\\miniconda3\\envs\\A1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RAF\\miniconda3\\envs\\A1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# extract the ethnicity predictions\n",
    "# (2)\n",
    "test_lbls_ethnicity = test_generator.labels[1]\n",
    "pred_lbls_ethnicity = np.argmax(ethnicity_pred, axis=1)\n",
    "\n",
    "# print the classification report for predicting ethnicity\n",
    "# (2)\n",
    "cr_ethnicity = classification_report(test_lbls_ethnicity, pred_lbls_ethnicity)\n",
    "print(cr_ethnicity)\n",
    "\n",
    "# extract the gender predictions where probabilities above 0.5 are considered class 1 and if not, class 0\n",
    "# (2)\n",
    "test_lbls_gender = test_generator.labels[2]\n",
    "gender_pred_binary = (gender_pred > 0.5).astype(int)\n",
    "\n",
    "# print the classification report for predicting gender\n",
    "#(2)\n",
    "cr_gender_binary = classification_report(test_lbls_gender, gender_pred_binary)\n",
    "print(cr_gender_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present prediction results on test data(5/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present your findings for 5 different runs by fine-tuning the hyperparameters. The results table must contain the following fields\n",
    "- A minimum of 5 hyperparameters that you have fine-tuned\n",
    "- Mean absolute error for age\n",
    "- Accuracy for ethnicity prediction\n",
    "- Accuracy for gender prediction\n",
    "Please use a table format similar to the one mentioned below when presenting the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hyperparameters                                                                                                        | Age(MAE) | Ethnicity(Accuracy) | Gender(Accuracy) |\n",
    "|------------------------------------------------------------------------------------------------------------------------|----------|---------------------|------------------|\n",
    "| batch_size = 16, epochs = 5, early_stop patience = 5, reduce_lr patience = 5, checkpoints save_best_only = True        | 245.0447 | 0.4818              | 0.7378           |\n",
    "| batch_size = 128, epoch = 4, early_stop patience = 3, reduce_lr patience = 2, checkpoint save_weights = False          | 420.0009 | 0.4240              | 0.5832           |\n",
    "| batch_size = 16, epochs = 5, early_stop patience = 5, early_stop restore_best_weights = True, reduce_lr min_lr 0.0001  | 309.2747 | 0.4533              | 0.6884           |\n",
    "| batch_size = 8, epochs = 3, early_stop patience = 3, reduce_lr min_lr = 0.00001, checkpoints save_weights_only = False | 443.5240 | 0.4253              | 0.6039           |\n",
    "| batch_size = 16, epochs = 1, early_stop patience = 3, reduce_lr factor = 0.01, reduce_lr patience = 2                  | 408.8803 | 0.4240              | 0.5230           |"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
